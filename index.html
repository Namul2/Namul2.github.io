<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>ByeongJin Kang</title>

    <meta name="author" content="ByeongJin Kang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/Byeongjin.jpg" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Byeongjin Kang
                </p>
                <p>I'm an undergraduate in <a href="https://www.skku.edu/skku/index.do" >Sungkyunkwan University</a>, majoring in Computer Science and Engineering. I'm interested in Reinforcement Learning and Robotics, especially in enabling robots to behave like humans. Currently, I'm working as an intern at <a href="https://youngwoon.github.io/">RLLAB</a> advisde by Prof. Youngwoon Lee.
                </p>
                <p>
                  previously, I worked as an intern at <a href="https://sites.google.com/view/yskim525">CSI LAB</a> advised by Prof. Yusung Kim.
                  
                </p>
                <p style="text-align:center">
                  <a href="mailto:qudwlskbj@gmail.com">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/Byeongjin-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/Namul2/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/Byeongjin.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Byeongjin.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                  The goal of my research is to <strong>"robots with intelligence"</strong>, enabling embodied agents to achieve <strong>self-improvement</strong> akin to human learning. In other words, I aim to develop agents that can autonomously understand their own capabilities, adapt to new tasks, and continuously refine their skills.
                  
                  <p></p>
                  
                  My current research focuses on the following key approaches:

                  <ul class="a">
                  <li> <strong>Self-Improvement Learning</strong>: 
                  Humans intuitively understand their own bodies and gradually adapt to new tasks even before receiving explicit external rewards. Inspired by this, I explore how intrinsic motivation can drive skill acquisition and adaptation in embodied agents, enabling them to improve even in the absence of direct supervision.

                  <p></p>

                  <li> <strong>Visual Representation Learning</strong>:
                  Learning robust visual representations is crucial for generalization in robotic perception. My research investigates how to extract meaningful features from high-dimensional sensory data, allowing embodied agents to interpret and interact with their environment efficiently.

                  <p></p>

                  <li> <strong>Test-Time Adaptation</strong>:
                  Unlike controlled simulation environments, the real world presents inherent challenges, including partial observability and dynamic uncertainties. Even well-trained models cannot execute tasks flawlessly in every scenario. I focus on developing test-time adaptation techniques that allow agents to dynamically adjust their behavior based on real-time feedback, ensuring robust and generalizable performance across diverse environments.
                  </ul>

                  By integrating these research directions, I aspire to bridge the gap between <strong>intelligence</strong> and <strong> cognition</strong>, creating adaptive and intelligent robotic systems capable of lifelong learning and self-improvement.
              </p>
            </td>
          </tr>
            <td style="padding:20px;width:100%;vertical-align:middle;line-height:10px">
              <h2 style="padding-bottom:0px">Research Experinces and Projects</h2>
              <!-- <p style="padding-top:0px">(* denotes equal contribution)</p> -->
            </td>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:-20px">
          </tr>
        </td>
      </tr>


      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          </video></div>
            <img src='images/biman.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <span class="papertitle">Complex Long horizontal task with Online Reinforcement Learning</span>

          <br>
              <font color="purple"><strong>Byeongjin Kang</strong></font>,
              CSI Lab team members
              
          <br>
          <em><strong>CSI LAB research internship project</strong><em> 
          <br>
          <!-- <a href="data/LLM_project_paper.pdf">project paper</a> / 
          <a href="https://github.com/SKKUWhiteBoard/WhiteBoard_LLM">code</a> -->
          <!-- <br> -->
          <p>
            This project explored online reinforcement learning for a complex long horizontal task using a main board and cables. It involved setting up a robust learning environment, efficient data collection, and training with pixel-based RLPD. While full success in online learning was not achieved, the project provided valuable insights into the challenges of real-time adaptation and laid the groundwork for future advancements in online reinforcement learning.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          </video></div>
            <img src='images/aug.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <span class="papertitle">Visual Robustness in Imitation Learning</span>

          <br>
              <font color="purple"><strong>Byeongjin Kang</strong></font>,
              CSI Lab team members
              
          <br>
          <em><strong>CSI LAB research internship project</strong><em> 
          <br>
          <!-- <a href="data/LLM_project_paper.pdf">project paper</a> / 
          <a href="https://github.com/SKKUWhiteBoard/WhiteBoard_LLM">code</a> -->
          <!-- <br> -->
          <p>
            This project focuses on applying action imitation learning to robotic manipulation tasks, aiming for visual robustness. It tests variations in the number of cameras and viewpoints while leveraging various vision techniques to ensure resilience against visual disturbances such as color changes, brightness variations, and blur in different environments. Experiments demonstrated a significant improvement in success rates, with the baseline model ACT achieving 10% in the training environment and 80% in different test environments.
          </p>
        </td>
      </tr>
    <!-- </table> -->

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          </video></div>
            <img src='images/project.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <span class="papertitle">Efficient Long Text Summarization Using an sLLM Pipeline</span>

          <br>
              <font color="purple"><strong>Byeongjin Kang</strong></font>,
              HoJae Kim, HunTae Kim, Joonyeol Choi, Minsu Kim, Saehun Chun
          <br>
          <!-- <em><strong>ICLR, 2025</strong><em>  -->
          <!-- <br> -->
          <a href="data/LLM_project_paper.pdf">project paper</a> / 
              <a href="https://github.com/SKKUWhiteBoard/WhiteBoard_LLM">code</a>
          <br>
          
          <p><em>
            This project develops a compact, edge-deployable LLM for summarizing video lecture transcripts efficiently. Instead of direct fine-tuning, it uses a segmentation-based approach, dividing transcripts into semantically related segments via cosine similarity. These are clustered using methods like KNN and DBSCAN, then summarized by a specialized 500M-parameter LLM. This approach reduces computational demands while maintaining high-quality summaries. Evaluation with ROUGE and BERTScore shows superior performance over baseline models. 
          </em></p>
        </td>
      </tr>
    </table>
    
    
    <tr>
      <td style="padding:20px;width:100%;vertical-align:middle" colspan="2">
        <p style="text-align:right">
          Website template from <a href="https://github.com/jonbarron/website">Jon Barron</a>.
        </p>
      </td>
  </body>
</html>
